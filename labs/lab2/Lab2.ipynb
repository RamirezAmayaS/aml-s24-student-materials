{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 - Regression, DiD, and Fixed Effects\n",
    "- **Author:** Suraj R. Nair ([suraj.nair@berkeley.edu](mailto:suraj.nair@berkeley.edu)) (based on past labs by Emily Aiken, Qutub Khan Vajihi and Dimitris Papadimitriou)\n",
    "- **Date:** February 24, 2024\n",
    "- **Course:** INFO 251: Applied machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics:\n",
    "1. Linear/ Multivariate Regression\n",
    "2. Dummy variables\n",
    "3. Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References: \n",
    " * [Statsmodels](http://www.statsmodels.org/stable/example_formulas.html#loading-modules-and-functions) \n",
    " * [Interpreting regression coefficients](https://dss.princeton.edu/online_help/analysis/interpreting_regression.htm)\n",
    " * [Card and Krueger (1994)](https://davidcard.berkeley.edu/papers/njmin-aer.pdf)\n",
    " * Fixed Effects:\n",
    "      - [Panel Data and Fixed Effects in Python](https://matheusfacure.github.io/python-causality-handbook/14-Panel-Data-and-Fixed-Effects.html)\n",
    "      - [Notes](https://www.jblumenstock.com/files/courses/econ174/FEModels.pdf) on fixed effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline  \n",
    "\n",
    "# The packages you'll need for regression models\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "Card and Krueger (1994) collected survey data on employment in fast food restaurants in New Jersey and Pennsylvania in 1992. The data for today's lab uses a subset of the variables they collected.\n",
    "\n",
    "- *UNIQUE_ID*: Unique ID for the restaurant interviewed\n",
    "- *PERIOD*: 0 for pre-period (March 1994), 1 for post-period (December 1994)\n",
    "- *STATE*: 0 for Pennsylvania, 1 for New Jersey\n",
    "- *REGION*: Region code: 1 = Southern NJ, 2 = Central NJ, 3 = Northern NJ, 4 = Northeast Philly suburbs, 5 = Easton area, 6 = NJ Shore\n",
    "- *CHAIN*: Chain restaurant code: 1 = Burger King, 2 = KFC, 3 = Roy's, 4 = Wendy's\n",
    "- *EMP*: Number of employees (fulltime or parttime)\n",
    "- *CO_OWNED*: 1 if company-owned\n",
    "- *BONUS*: 1 if employees get a signing bonus\n",
    "- *HRSOPEN*: Hours open per day, up to 24\n",
    "- *NREGS*: Number of registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fastfood.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a variable identifying the pre-treatment period\n",
    "pre = df[df['PERIOD'] == 0].copy()\n",
    "post = df[df['PERIOD'] == 1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Univariate Regression\n",
    "\n",
    "Linear regression provides us a concise summary of one variable as a function of another variables(s) through two types of parameters - the slope and the intercept. To review linear regression, we'll start by exploring the relationship between employment and the number of hours a restaurant is open\n",
    "in the pre-period.\n",
    "\n",
    "#### 2.1 Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlation between number of rooms and median housing price.\n",
    "np.corrcoef(pre['HRSOPEN'], pre['EMP'])[0][1]\n",
    "\n",
    "#Pandas also has a built correlation function\n",
    "# pre[['HRSOPEN', 'EMP']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.scatter(pre['HRSOPEN'], pre['EMP'], alpha=.2)\n",
    "plt.xlabel('Daily Hours Open', fontsize='large')\n",
    "plt.ylabel('Number of Employees', fontsize='large')\n",
    "plt.title('Hours Open vs. Employees', fontsize='x-large')\n",
    "plt.xlim(6.9, 24.1)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Estimating a regression with np.polyfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the regression\n",
    "x, y = pre['HRSOPEN'].values, pre['EMP'].values # x is the input variable, y is the output variable\n",
    "slope, intercept = np.polyfit(x, y, 1) # 1 is the degree\n",
    "\n",
    "# Scatterplot with the regression line\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.scatter(pre['HRSOPEN'], pre['EMP'], alpha=.2)\n",
    "plt.plot(x, slope*x + intercept, color='darkgrey')\n",
    "plt.xlabel('Daily Hours Open', fontsize='large')\n",
    "plt.ylabel('Number of Employees', fontsize='large')\n",
    "plt.title('Hours Open vs. Employees', fontsize='x-large')\n",
    "plt.xlim(6.9, 24.1)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Interpretation of the slope and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The slope of the line is {np.round(slope, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How would you interpret this value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The intercept of the line is {np.round(intercept, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How would you interpret this value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Estimating a regression with statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax option 1\n",
    "x, y = pre['HRSOPEN'].values, pre['EMP'].values # x is the input variable, y is the output variable\n",
    "x = sm.add_constant(x) # Add a constant for the intercept term\n",
    "model1 = sm.OLS(y, x).fit() # Note the order of y folowed by x!\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax option 2\n",
    "model2 = smf.ols(formula='EMP ~ HRSOPEN', data=pre).fit() # Automatically includes the intercept term\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Categorical Data\n",
    "\n",
    "Now, we'll experiment with categorical data by examining the relationship between EMPTOT (the number of employees) and CHAIN (the fast food chain category) in the pre-period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check values of CHAIN\n",
    "pre['CHAIN'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy variables for CHAIN\n",
    "dummy_pre = pd.get_dummies(pre, columns=['CHAIN']).head() # Pandas' default is not to drop a column\n",
    "dummy_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dummy variables for CHAIN and drop one column\n",
    "dummy_pre = pd.get_dummies(pre, columns=['CHAIN'], drop_first=True).head() # Drop a column\n",
    "dummy_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression with a dummy variable: Syntax option 1\n",
    "x = pd.get_dummies(pre[['CHAIN']], columns=['CHAIN'], drop_first=True)\n",
    "x = sm.add_constant(x)\n",
    "y = pre['EMP']\n",
    "print(sm.OLS(y, x).fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: \n",
    "\n",
    "- How do we interpret the coefficients on the variable(s) CHAIN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression with a dummy variable: Syntax option 2\n",
    "\n",
    "# Statsmodels formula API automatically drops one of the dummies\n",
    "print(smf.ols(formula='EMP ~ C(CHAIN)', data=pre).fit().summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Now run the regression again, this time dropping the constant. What do you observe? How have the coefficients changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: drop the constant\n",
    "print(smf.ols(formula='EMP ~ C(CHAIN) - 1', data=pre).fit().summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multivariate Regression\n",
    "\n",
    "Now let's look at some other covariates: The number of registrations, whether or not employees get a bonus, and the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax 1\n",
    "X = sm.add_constant(pre[['HRSOPEN', 'NREGS', 'BONUS']]) # X is capitalized since it's now a matrix\n",
    "y = pre['EMP']\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Syntax 2\n",
    "model = smf.ols(formula='EMP ~ HRSOPEN + NREGS + C(REGION)', data=pre).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: Interpret each of the regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. On average, prior to the wage increase, is the average employment in New Jersy and Pennsylvania similar? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate the average change in employment, for the following groups (difference in means):\n",
    "    \n",
    "    - Pennsylvania v/s New Jersey (Post-period only, i.e PERIOD = 1)\n",
    "    - Pennsylvania v/s New Jersey (Pre-period only, i.e PERIOD = 0)\n",
    "    - Pre v/s Post in Pennsylvania\n",
    "    - Pre v/s Post in New Jersey \n",
    "    - Differences-in-difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now, let's do the same thing, but using linear regression! Let's focus on differences between Pennsylvania and New Jersey in the pre-period only. What do you observe?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Let's see what happens when we add a control variable. Let's control for the number of hours (HRSOPEN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Plot the regression line/ line of best fit in the treatment and the control groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Let's finish with a visual assessment of trends in EMP before and after the wage increase, in T and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's calculate the mean for the pre and post periods, in both the treatment and control groups. \n",
    "control_pre = \n",
    "treatment_pre = \n",
    "control_post = \n",
    "treatment_post = \n",
    "\n",
    "\n",
    "# Now, let's plot this. \n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.scatter([0, 1], [control_pre, control_post], s=200)\n",
    "plt.plot([0, 1], [control_pre, control_post], label='Control (Pennsylvania)')\n",
    "plt.scatter([0, 1], [treatment_pre, treatment_post], s=200)\n",
    "plt.plot([0, 1], [treatment_pre, treatment_post], label='Treatment (New Jersey)')\n",
    "plt.legend(loc='best', fontsize='large')\n",
    "plt.xlabel('Time (Pre vs. Post)', fontsize='large')\n",
    "plt.ylabel('Average Employees', fontsize='large')\n",
    "plt.title('Employees Over Time', fontsize='x-large')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR NEXT WEEK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differences-in-differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use a differences-in-differences regression specification to estimate the impact of the increase in the minimum wage in New Jersey (state == 1) between the pre- and the post-period (period==1). \n",
    "\n",
    "Remember the diff-in-diff regression specification: Y = B0 + B1 * Time + B2 * Intervention + B3*(Time*Intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: Interpret the regression coefficients in terms of the impact of the minimum wage change on employment.\n",
    "\n",
    "**QUESTION**: Why might you want to add control variables to this regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Interaction Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interaction term captures the notion that the value of a variable is influenced by the value of another variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = smf.ols(formula='EMP ~ HRSOPEN + BONUS + HRSOPEN * BONUS ', data=pre).fit()\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: Interpret the coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: Create a plot which demonstrates how the variable BONUS influences the value of HRSOPEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6: Fixed Effects Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a toy dataset for this example, with these variables:\n",
    "\n",
    "    - city: New York, Chicago, San Francisco, Washington D.C\n",
    "    - year: 2020, 2021, 2022, 2023, 2024\n",
    "    - quantity: the amount purchased (of some arbitrary good)\n",
    "    - price: the cost of the arbitrary good, varying by year and city. \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_panel = pd.DataFrame({\n",
    "    \"quantity\": [25, 24.3, 23, 20,\n",
    "                 15, 13.8, 12.5, 13,\n",
    "                 20, 19, 18, 19,\n",
    "                 22, 19.5, 19, 19,\n",
    "                ],\n",
    "    \"price\": [5.0, 5.34, 5.47, 5.51, \n",
    "              4.01, 4.35, 4.43, 4.43, \n",
    "              4.50, 4.62, 4.70, 4.89, \n",
    "             4.80, 4.90, 4.95, 5.25\n",
    "             ],\n",
    "    \"year\":[2020, 2021, 2022, 2023]*4,\n",
    "    \"city\":  ['New York']*4 +  \n",
    "             [\"Chicago\"]*4 + \n",
    "             [\"San Francisco\"]*4 + \n",
    "             [\"Washington D.C.\"]*4\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore a cross-section of this data, say in the year 2022.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### View the data\n",
    "\n",
    "df_panel[df_panel['year'] == 2022]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply looking over this data, it actually appears the quantity purchased appears to increase along with prices. Does that make sense?. \n",
    "\n",
    "What might explain this? On the one hand, perhaps the quality of the good is higher in certain cities. For example, if the **good** in question is a bagel, perhaps the best bagels are found in New York (ahem, Boichik)? Alternatively, there might simply be a high demand for bagels in New York, thus explaining the high prices. \n",
    "\n",
    "But simply put, we can't say much about the role of price here -- since we do not have data for quality, or bagel obsession.. Running a regression to further examine the relationship between quantity and price is likely to thus suffer from omitted variable bias.\n",
    "\n",
    "To hammer home this point, let's explore the relationship between quantity and price using a univariate regression, across the entire sample. What do you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = smf.ols(\"quantity ~ price\", data = df_panel).fit()\n",
    "\n",
    "sns.scatterplot(data = df_panel, x=  'price', y = 'quantity', hue = \"city\")\n",
    "plt.plot(df_panel['price'], m.fittedvalues, \"k-\", alpha = 0.5, label=\"Regression Line\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Quantity\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine the full dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_panel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that as price increases, the quantity purchased decreases **within** each city. This is reasonable, as we would expect the demand to fall as price increases.\n",
    "\n",
    "This provides the underlying intuition for fixed effects. In the cross-section we saw earlier, a regression that primarily relied on variation across cities is problematic, due to omitted variables bias. The solution is to focus on **within** city variation, relying on the panel structure of the data to remove the effect of omitted variable bias.\n",
    "\n",
    "We still have to make a key assumption here, however. What is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine a simple fixed effects model, where we eliminate the unobserved variation across cities, and focus only on within city variation. A simple way to achieve this, as you saw in lecture, is to add a dummy variable for each city. So let's go ahead and try that below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#C() is used to tell statsmodels that the variable in question is a categorical/ factor variable\n",
    "fe = smf.ols(\"quantity ~ price + C(city)\", data=df_panel).fit()  \n",
    "\n",
    "df_panel['y_hat'] = fe.fittedvalues\n",
    "\n",
    "sns.scatterplot(data = df_panel, x = 'price', y = 'quantity', hue = 'city')\n",
    "for city in df_panel[\"city\"].unique():\n",
    "    plt_df = df_panel[df_panel[\"city\"] == city]\n",
    "    plt.plot(plt_df['price'], plt_df['y_hat'], \"k-\", alpha = 0.5)\n",
    "\n",
    "plt.title(\"Fixed Effect Model\")\n",
    "plt.xlabel(\"Quantity\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend(loc = \"best\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are effectively fitting one regression line per city. This is what the ''city'' fixed effect does -- it controls for the average (time invariant) differences across cities (in observable/ unobservable variables). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
