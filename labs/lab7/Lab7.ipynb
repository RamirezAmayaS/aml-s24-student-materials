{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7 - Linear Models, Cost Functions, and Regularization\n",
    "- **Author:** Suraj R. Nair([suraj.nair@berkeley.edu](mailto:suraj.nair@berkeley.edu))\n",
    "- **Date:** February 28, 2024\n",
    "- **Course:** INFO 251: Applied machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives:\n",
    "At the end of this lab, you will be able to...\n",
    "- Train a linear model end-to-end by defining the model, the cost function, and the regularization, taking partial derivatives, and running gradient descent\n",
    "- Understand the differences between common loss functions\n",
    "- Compare Ridge and LASSO regularization, and optimize both with gradient descent\n",
    "- Use cross validation to find the optimal regularization parameter for Ridge and LASSO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics:\n",
    "1. Cross validation to find the optimal regularization parameter\n",
    "\n",
    "**NOTE:** The other topics in this lab are covered in the lecture and participatory activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "1. [Loss functions cheat sheet](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html)\n",
    "2. [Gradient descent for linear regression lecture notes](https://www.cs.toronto.edu/~rgrosse/courses/csc321_2017/readings/L02%20Linear%20Regression.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cross validation to find the optimal regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data, drop columns with nulls\n",
    "df = pd.read_csv('auto.csv')\n",
    "outcome = 'acceleration'\n",
    "features = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'year']\n",
    "for feature in features:\n",
    "    df[feature] = df[feature].apply(lambda x: np.nan if x == '?' else float(x))\n",
    "df = df.dropna(subset = [outcome] + features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide into random train set (75%) and test set (25%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, test = train_test_split(df, test_size=.25, shuffle=True, random_state=1)\n",
    "print('Number of training observations: %i' % len(train))\n",
    "print('Number of testing observations: %i' % len(test))\n",
    "\n",
    "# Separate output from inputs\n",
    "x_train, y_train = train[features], train[outcome]\n",
    "x_test, y_test = test[features], test[outcome]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETE:  Train a linear regression on the training set, produce predictions on the train + test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## COMPLETE: Initialize the model\n",
    "model = \n",
    "\n",
    "## COMPLETE: Fit the model on the training data\n",
    "\n",
    "\n",
    "# COMPLETE: Generate predictions on training + test set\n",
    "yhat_train = \n",
    "yhat_test = \n",
    "\n",
    "# Print Results\n",
    "print('Linear regression r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('Linear regression r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETE:  Train a linear regression on the training set, produce predictions on the train + test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a LASSO regression on the training set, produce predictions on the train + test set\n",
    "\n",
    "## COMPLETE: Initialize the model (set alpha = 1)\n",
    "\n",
    "## COMPLETE: Fit the model on training data\n",
    "\n",
    "\n",
    "## COMPLETE: Generate predictions on the training + test data\n",
    "yhat_train = \n",
    "yhat_test = \n",
    "\n",
    "\n",
    "## Print Results\n",
    "print('Linear regression r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('Linear regression r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPLETE: Use 5 fold cross validation to determine the optimal LASSO on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state = 12)\n",
    "\n",
    "lmbdas = np.logspace(-3, 1, 20)\n",
    "scores = []\n",
    "for lmbda in lmbdas:\n",
    "    ## COMPLETE: Initialize the model with lmbda\n",
    "    model = \n",
    "    ## COMPLETE: Get the main CV score (use cross_val_score)\n",
    "    cv_score = cross_val_score( ... )  ## fill in the arguments here\n",
    "    scores.append(np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot cross-validated r2 as a function of regularization strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 5))\n",
    "ax.scatter(lmbdas, scores)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Lambda (log scale)')\n",
    "ax.set_ylabel('Mean Cross-Validated RMSE')\n",
    "ax.set_title('RMSE vs. Regularization Strength')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get best lambda value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximum cross-validated r2: %.2f' % np.max(scores))\n",
    "best_lmbda = lmbdas[np.argmax(scores)]\n",
    "print('Lambda associated with best maximum cross-validated r2: %.2f' % best_lmbda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit LASSO with optimal lambda on train set, predict on training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model\n",
    "model = Lasso(alpha = best_lmbda)\n",
    "\n",
    "# Fit the model on training data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Predict on training + test data\n",
    "yhat_train = model.predict(x_train, y_train)\n",
    "yhat_test = model.predict(x_test, y_test)\n",
    "\n",
    "print('Linear regression r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('Linear regression r2 on test set: %.2f' % r2_score(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative: Use sklearn's built-in LassoCV functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LassoCV(alphas = lmbdas, cv = kf, random_state = 12) ## Note: no option to shuffle, so use the cv object from above. \n",
    "model.fit(x_train, y_train)\n",
    "yhat_train = model.predict(x_train)\n",
    "yhat_test = model.predict(x_test)\n",
    "\n",
    "print('Linear regression r2 on training set: %.2f' % r2_score(y_train, yhat_train))\n",
    "print('Linear regression r2 on test set: %.2f' % r2_score(y_test, yhat_test))\n",
    "print('Chosen lambda value: %.2f' % model.alpha_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
